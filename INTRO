

= DRP, Directed Ruby Programming

<em>N.B., all example code below can be found in the examples/intro directory</em>

Directed Programming is a new generative programming technique developed by Christophe McKeon which is a generalisation of Grammatical Evolution (http://www.grammatical-evolution.org) allowing one not only to do GE, but also to do Genetic Programming (http://www.genetic-programming.org) in pure Ruby without explicitly generating a program string as output. DP even allows you to set up hybrids of GP and GE where part of a GE subtree is calculated using normal Ruby functions/operators/etc. via. GP. DRP is the first ever implementation of DP and is written in pure Ruby. 

DRP however manages to dispense with two problems which affects these two systems, at least in their canonical forms. It cirumvents the so called closure problem of GP simply by stepping over it, a property which it neatly inherits from GE. It also avoids the aborted run problem of GE by having a maximum allowed recursive depth for each expression in a production rule. DRP also allows for a kind of meta-evolution in which rules can be evolved right out of the grammar, or take on a more or less significant a role. It accomplishes this by weighting the right hand sides of rules, as well as limiting the maximum recursive depth of a given rule, which can be evolved right down to zero.

GE and DRP are especially well suited to interactive evolutionary/generative applications because they allow arbitrarily tight control over program structure and output. This is important in my view because in interactive systems the biggest bottleneck by far is the fitness function, i.e. the user, and so it is advantageous to be able to *easily* 'engineer' the specification so as to favour certain outcomes. There simply is not enough time for the large populations and many generations used in non-interactive systems. GE is in fact used in several such systems[http://projects.csail.mit.edu/emergentDesign/genr8]. And then of course Ruby itself is no hot-rod, which for interactive sytems is nowhere near as much of a problem as in strictly engineering applications. 

=== A Quick Intro to Genetic Programming

GP in it's most commonly known form is an evolutionary computation technique which evolves LISP S-expressions, which are similar to Abstract Syntax Trees if you know about compiler internals. GP was invented and pioneered by John Koza.

First a population of trees using the user supplied operators is randomly generated. The evolutionary aspect of it involves running the S-Expressions against some fitness function and determining which are the best performing, which then become the most likely to have 'offspring'. Offspring are generated by snipping off subtrees of both parents and switching them so that each parent gets the subtree of the other 'grafted' back onto the splice point. Other evolutionary operators are also sometimes used such as point mutation where a single node such as an operator, or a constant value (which in GP have the beautiful apelation of 'ephemeral random constants'), are mutated.

As you can imagine if in a GP system you have operators which return values of incompatible types, you cannot just snip subtrees anywhere you like and expect the program to run, this is what is usually called the closure problem of GP. There have been various solutions to the problem put forth including several extensions to GP, but the most interesting, and certainly the most elegant, in my view are Lee Spector's PUSH language (which is not relevant to DRP), and Grammatical Evolution.

=== A Quick Intro to Grammatical Evolution

GE is a generative programming technique which unlike GP or PUSH separates the search algorithm from the program representation. For this reason the word evolution in it's name is a bit of a misnomer since other search algorithms besides evolutionary ones can be used, as long as they involve the generation of streams of integral values. It was pioneered by Connor Ryan, JJ Collins and Micheal O'Neil.

GE allows for the automatic generation of programs in any language. It does this by using BNF grammars, as follows:

 <foobar> ::= 'foo ' <foobar>
 <foobar> ::= 'bar!'

The above grammar specifies a language consisting of zero or more 'foo's followed by a 'bar!'.

For instance, <tt>'foo foo foo bar!'</tt>, <tt>'foo bar!'</tt>, and <tt>'bar!'</tt> are strings in the language, but <tt>'bar! foo'</tt> is not. First the algorithm must be given a start symbol, which in our above language is easy because we only have one left hand side, namely <tt><foobar></tt>, and so we have no choice. But we have two possible right hand sides, and so the algorithm must make a choice between the two possibilities. GE usually does so by iterating over values in a Genetic Algorithm, wrapping back to the beginning if need be, and uses the current integral value in the iteration modulo the number of choices to index into the list of possible right hand sides and make the choice.  

This brings us to GE's main problem. What if we had a freak GA which consisted of all even numbers. Using the 'foo bar!' example above, for all of x in the GA, 2 modulo x would yield 0, so that the first right hand side would always be chosen, and the algorithm would never halt. But it doesn't have to be that extreme, a GA can be produced which will eventually halt but which still runs long enough to generate a monstrously long machine/process halting output string. GE solves this by simply limiting the number of times that the GA can be wrapped over, and aborting any runs which exceed the limit.

Another problem is that in GE, for any given 'gene', each right hand side always has the same probability as it's siblings of being chosen. This means that if some RHS is more or less important to the solution, it will still have the same arbitrarily imposed importance as the other choices, possibly detrimentally to the efficacy of the algorithm. The GE team have recently done work on evolving the grammars themselves using GE in order to alleviate the problem, called GE by GE, but the problem still remains to a degree, in that the RHSs which make it into the second grammar are still equally weighted. DRP has a different take on this kind of meta-evolution.

== The DRP System

=== A Quick Intro

DRP grew out of a first attempt I had called Easy GE, which was a GE system which did not allow for direct GP the way DRP does, but which used a few of the improvements to GE which I'll describe below. It had a hand-rolled parser/scanner and interpreter for a little mini-language to represent BNF grammars. At one stage I decided that it would be really great to add parameterization, where rules could be invoked, and passed arguments which could themselves be rules. Although it looked much cleaner in my language, it went something like:

 <foo> ::= 'foo' <foo(<bar>)>
 <bar> ::= ...

This would be useful for certain kinds of output languages, like XML where you might want to pass a tag_name determined by a rule, to another rule, say xml_tag, which would use the name for both the opening and closing tags. As I considered various hypothetical situations, some in languages more expressive than XML, I determined that it would be a really great feature. I also wanted to add a few data types and operators to the language to be able to do some simple math at the generation stage, for numbering identifier names and doing things which very static languages make it hard to do at run-time. But to add all of those things comes very close to just implementing another full scale language where rules are basically just functions which may or may not return strings. Why not just leverage the Ruby interpreter itself then, which is what I did, dividing the number of lines in the project by 5.

DRP is designed for extreme ease of use. I'm a big believer in ease of use and 'hand-holding' in documentation. Why waste time reading code when a simple explanation will usually do. If you are considering adopting a project out of a choice of 10, you are much more likely to choose the well documented one, but I digress. Here's an example of the first grammar above using DRP:

 :include:toy_example.rb

Don't rub your eyes, it's not your monitor malfunctioning either, foobar is defined twice, and some metaprogramming magic fixes it such that whenever foobar is called one of the two <em>rule methods</em> (methods between begin and end rule statements) will be called according to how their weights and max_depths have been set, which in the above example are set to the global defaults. 

=== Codons

In DRP 'genes' are floating point numbers in the range 0..(1-Float::EPSILON) and are called codons. I prefer the word codons because it has fewer biological overtones, as similarly to GE, it can run using any number of search algorithms, not just genetically inspired ones. For instance Particle Swarm Optimization (http://www.swarmintelligence.org) is a very good match with DRP.

You may have noticed that in the above toy example there is no code for a GA or PSO algorithm in sight. That's because to supply a stream of codons yourself, all you have to do is override the default next_codon method, which by default simply calls and returns rand. There is another method which you can override, 'next_meta_codon' which is called for setting weights and max_depths. By default next_meta_codon simply calls next_codon, so you should only override it if you want to separate the 'meta evolutionary' part of your search algorithm from the code generation part.

=== Setting Max Depths

As described above, the main problem with GE is that there can be any number of aborted runs in one generation or iteration of the search algorithm. This is due to the fact that a BNF grammar does not have at it's disposal a mechanism for specifying the maximum recursive depth which any one rule can take. BNF grammars were initially developed for parsing Algol-60 programs, and then were adopted for a wide variety of other tasks, usually of a parsing or descriptive nature, as opposed to generative one. If maximum recursive depths are allowed for individual rule methods not only does GE's main problem disappear, but a new and powerful method of controlling the form of the generated code becomes available.

In DRP all rule methods have individually assigned maximum recursive depths, even rule methods with the same name. In the following example two different simple static max_depths are assigned to two rule methods called 'foo'. Because both rule methods have the same name, first the process of choosing which rule method to call is performed every time the method foo is called (described in more detail in the next section). Since they have the same weight they have an equal chance of being called for any given codon, which is what accounts for the different random ordering of the output string for each top level call. Because there is no terminating condition for the recursive call the only thing stopping the recursion is the max_depth, which also accounts for the number of each type of foo printed. You will also notice that max_depth works just as well for indirect recursion as for direct recursive calls.

This example also introduces the default_rule_method method, which should always be defined as a normal method (not between begin_rules and end_rules). It is called whenever there are no more available rule_methods of a given name because they have exceeded their max depths. There is a default default_rule_method defined for you which just returns nil.

 :include:max_depths_example.rb

Which prints the following to the screen:

 foo2 foo1 foo2 foo2 foo1 bar!
 foo1 foo1 foo2 foo2 foo2 bar!
 foo2 foo2 foo1 foo1 foo2 bar!

In the following example the singular max_depth class method defines the maximum depth for both of the rule methods which follow. It essentially says, for all following rule methods call next_meta_codon and map the returned codon to the range given, at object initialization time, i.e. each object of class MaxDepthsExample2 will be given different maximum depths for each of it's foo rule methods.

 :include:max_depths_example_2.rb
 
Which prints the following to the screen:

 foo2 foo1 foo1 foo1 foo2 
 foo2 foo1 foo2 foo1 foo1 
 foo1 foo2 foo2 foo1 foo1 

 foo1 foo2 
 foo1 foo2
 foo2 foo1

 foo2 foo2 foo2
 foo2 foo2 foo2
 foo2 foo2 foo2

Note that in the third set of output strings foo1 has been 'evolved' right out of the grammar, because the range started at 0.

There is also a way of specifying a function to use for the mapping by writing

 max_depth x..y, :name_of_function

... but for the moment only :i_linear is implemented, so there is no reason to use it.

There is a third way of setting the maximum depth which works exactly like the range example in terms of how and when it sets depths for rule methods. It takes a user supplied block and requests enough meta_codons to satisfy the arity of the block. If the arity is 0 then no meta_codons are requested.

 max_depth { |x,y,z| use_meta_codons_to_define_max_depth(x,y,z) }

=== Setting Weights

In the following example, max_depth is set to 3 for both rule methods, but their weights are set individually. Weights are normalized every time a choice must be made between several rule methods. For some given array of weights, normalization simply divides each weight by the sum of all the weights. The next_codon method is then called to make a choice according to the normalized weights.

It may seem inefficient to normalize for every choice, but the weights and the relationship between weights are constantly changing, both because rule methods are constantly dropping out due to exceeding their max_depth, and also because weight can be set to be a function of the current depth, but more on that in a moment.

You will notice that in the output foo2 has a much greater chance of being picked at first, but once it has exceeded its max_depth, it is no longer an option so foo1 is then called until it also exceeds its max_depth.

 :include:weights_example.rb

Which prints the following to the screen:

 foo2 foo2 foo2 foo1 foo1 foo1
 foo2 foo2 foo2 foo1 foo1 foo1
 foo2 foo1 foo2 foo2 foo1 foo1

 foo2 foo2 foo2 foo1 foo1 foo1
 foo2 foo2 foo2 foo1 foo1 foo1
 foo1 foo2 foo1 foo2 foo2 foo1

 foo2 foo2 foo2 foo1 foo1 foo1
 foo2 foo2 foo2 foo1 foo1 foo1
 foo2 foo2 foo2 foo1 foo1 foo1

You can also map a codon to a Range, or supply a block. In both cases it works just like with max_depth. The weights are set for each rule method of each new object calling next_meta_codon when need be. In the below example the first set generated were fairly evenly weighted, the second weighted towards, foo2, and the third, foo1.

 :include:weights_example_2.rb

Which prints the following to the screen:

 foo1 foo2 foo2 foo1
 foo1 foo2 foo2 foo1
 foo1 foo2 foo1 foo2

 foo2 foo2 foo1 foo1
 foo1 foo2 foo1 foo2
 foo2 foo2 foo1 foo1

 foo2 foo1 foo1 foo2
 foo1 foo1 foo2 foo2
 foo1 foo1 foo2 foo2

=== Setting Weights as a Function of the Current Depth

This feature *is* powerful. It allows you to generate a weight for any given rule method, as a mapping of the current depth as measured against the maximum allowable depth, to a Range. And it allows you to evolve the Range's min and max values themselves using next_meta_codon! 

In English that means that if some rule method has a max_depth of 3 and you supply a Range of 1..2, then counting from 0, when the rule_method is at a recursive depth of 0 it will have a weight of 1, and when at a depth of 1 going on 2, it will have a weight of 1.5 and when at a depth of 2 going on 3, it will have a weight of 2, that is unless you specify some non-linear mapping.

If you supply two Ranges, then at object initialization time, 2 codons are pulled out of next_meta_codon, one for each Range to set the min and max of the Range used to calculate the weight at code generation time. You can follow the Range or Ranges with a symbolic function name, which in both cases is used to map the current depth to a weight at code generation time. Note that in the second case the function is not used to affect the mapping of the two meta codons to the min and max values, which is always just a linear mapping.

In the following example the lists of 'foo ... bar!' are generally longer than the lists of 'mama ... mia!', where both mama rule methods have a weight of 1, yet they are constrained from reaching a length of 25 'foo's, because 'bar!', also with a weight of 1, becomes more and more likely to be picked as the first foo rule method approaches it's max_depth.

 :include:weight_fcd_example.rb

Which prints the following to the screen:

 foo foo foo foo foo foo foo foo foo foo foo bar!
 bar!
 foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo bar!

 mama mia!
 mama mama mama mia!
 mama mia!

 foo foo foo bar!
 foo foo foo foo foo foo foo foo foo foo foo foo bar!
 foo foo foo bar!

 mia!
 mama mia!
 mia!

 bar!
 foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo bar!
 foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo foo bar!

 mia!
 mama mama mia!
 mia!

You can also supply a block to weight_fcd. The block should accept the max_depth of the rule method as a parameter, and should return a proc or lambda which will be called whenever a weight is needed for the rule method and passed the current depth, something like:

 weight_fcd { |the_max_depth|
               ...   
               proc {|the_depth| ... }
            }                      

Note that the weight is only ever calculated, and the weights normalized if there is a choice to be made. If there is only one rule method to choose from, then weights are not needed, and hence not calculated. If there are no rule methods, then default_rule_method is called, and if all the weights sum to 0, then they are all given an equal chance of being picked according to a next_codon. This last paragraph pertains to weights specified through both the weight and weight_fcd methods. But to make it more explicit...

=== El Corazon

For those who like the aroma of internal organs, this is the heart of DRP (don't call this stuff directly). After rule methods are culled for having exceeded max_depth (<tt>meth.expressed?</tt>), if there are more than one rule methods left, they are then passed to __drp__choose__method for the choice to be made. <tt>meth.weight</tt> is first called to get all the weights, some of which are calculated on the spot, then the weights are normalized and arranged to make a roulette wheel style of selection possible using next_codon.   

 ...

 useable_methods = @__drp__rule__methods[name].select do |meth|
   meth.expressed?
 end

 case useable_methods.size

   when 0
   default_rule_method *args          

   when 1
   __drp__call__method(useable_methods.first, args)

   else
   __drp__call__method(__drp__choose__method(useable_methods), args)

 end

 ...

 def __drp__choose__method useable_methods

   weights = useable_methods.collect do |meth|
     meth.weight
   end
   scale_by = weights.inject(0) do |weight, prev|
     prev + weight
   end

   weights = if scale_by == 0
     sz = weights.size
     weight = 1.0/sz
     prev_weight = 0
     Array.new(sz) do 
       prev_weight = weight + prev_weight
     end
   else
     prev_weight = 0
     weights.collect do |weight|
       prev_weight = weight / scale_by + prev_weight
     end
   end
     
   index, codon = -1, next_codon
   weights.detect do |weight| 
     index += 1;
     codon < weight
   end

   useable_methods[index]

 end

=== Parameterization, Or, Rule Methods are Really Just Ruby Methods

The following example just displays how rule methods in DRP behave for the most part just like regular Ruby methods. Note that if you have parameterized rule methods then if you supply a default_rule_method, then it should have the right arity. The default default_rule_method accepts any number of args and returns nil.

 :include:parameterization_example.rb

Which prints the following to the screen:

 [<1>[[<3><3><<6>>!!]]]
 [<1><1><1>[[<<6>>!!]]]
 <0><0><0>[[[<<6>>!!]]]

=== Odds & Ends

This example demonstrates the many bells and whistles DRP makes available to you, as well as setting up a simple next_codon method similar to what might be used with a GA. The map method gets a next_codon and maps it linearly to the given Range, unless a function name is specified as a second argument, in which case it uses that function for the mapping. You can also pass a block to map. Note that you can query for depth and max_depth from within rule methods.

 :include:odds_and_ends.rb

Which prints the following to the screen:

 querying for the max_depth:
 max_depth = 4

 simple depth example:
 1 2 3 4 !

 indirect depth example:
 1 1 2 2 3 3 4 4 !

 map a range:
 9.7869297362342 1.72293103036786 4.44993903945105 1.94575318883587 !

 map an integer range:
 sunset hotpants lollypop hotpants !

 map a block:
 3.6621640486161 0.461957811182177 3.8542419427911 0.972153552533642 !

 you can even get the next_codon: 0.164435008276921,
 and next_meta_codon: 0.936878472838206

=== Bringing it All Together, an Example Using an HTML Canvas Tag

The below is what a real world example might look like, using many of the features of DRP. Of course you would normally want it to be interactive using a GA or something. Note that IE currently does not support the canvas tag, but Firefox, Safari, and Opera do. 

 :include:canvas_example.rb

Which generates http://drp.rubyforge.org/canvas_example.html

=== Conclusion

I hope that I have made everything clear, please feel free to contact me if you have any questions, or better yet, improvements to this file. You may also want to have a look through the test directory, as that may give you a few more hints as to what behaviour I expect of the system. Cheers, and Happy Hacking!

 Copyright (c) 2006, Christophe McKeon
 Software License: Distributed under the GNU GPL, see LICENSE
 Documentation and Website: Creative Commons Attribution-NonCommercial-ShareAlike 2.5 License
